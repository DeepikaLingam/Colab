{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S1J-LcUhrlBg"
   },
   "source": [
    "# **Problem Statement**: \n",
    "Given the Board Game reviews, the below snippets of code attempts to predict the rating of the review. \n",
    "\n",
    "Test and Train data are divided in the ratio of 3:7. \n",
    "\n",
    "30% of the entire data belongs to test and 70% of data belongs to train.\n",
    "\n",
    "# **Challenges Faced**\n",
    "\n",
    "*   Size of the data\n",
    "*   NULL values\n",
    "*   RAM and hardware limitations\n",
    "*   Execution time limits\n",
    "*   Distribution of data\n",
    "*   Continuous values\n",
    "\n",
    "# **How did I overcome challenges?**\n",
    "*   The size of the data was too large to process in reasonable time. To overcome this, whenever I have used sklearn predefined functions, I let the parameters have default values. For custon functions, I have taken only some part of the data.\n",
    "*   This is a very classic text classification problem. Comments have null values that were affecting the input of the classifiers. I have removed all the null values because there of no importance. While vectorizing the data, I have removed extra white spaces.\n",
    "*   Due to limited RAM, I have grouped my code into blocks that are dependent. Example: For ensemble methods, I have taken voting from 3 different classifiers and made sure that all the 3 classifiers and ensemble are ran together. Remaining snippets of code are independent of each other, thus running them in different sessions did not affect\n",
    "*   Considering the size of the data, the execution time of each classifier is reasonably high. To overcome this, I have made used of pipeline functions in sklearn instead of executing all the elements separately.\n",
    "*   Distribution of values for different class labels(Rating values) is very random and not uniform. This was the main reason affecting the accuracy. This was one challenge that taught me how real world data is. I have tried different kinds of models to observe what fits better.\n",
    "*   The rating column in the data have continous values. For classification, continuous values are difficult to deal. It is almost impossible to classify in continuous values. To overcome this, I have converted it into integers thus obtaining discret values for rating.\n",
    "\n",
    "# **How to choose the right ratio for train and test?**\n",
    "unfortunately, there are no clear rules about what ratio to use. Personally I like 70-30, but this is a subjective choice. The tradeoffs are as follows:\n",
    "\n",
    "\n",
    "*   More training data is nice because it means your model sees more examples and thus hopefully finds a better solution. If you have a tiny training data set your model won’t be able to learn general principles and will have bad validation / test set performance (in other words, it won’t work.)\n",
    "*   More validation data is nice because it helps you make a better decision about which model is “The Best.” If you don’t have enough validation data, then there will be a lot of noise in your estimate of which model is “The Best” and you might not make a good choice.\n",
    "\n",
    "\n",
    "*   More test data is nice because it gives you a better sense of how well your model generalizes to unseen data. If you don’t have enough test data, your final assessment of the model’s generalization ability might not be accurate.\n",
    "(Read More on: https://glassboxmedicine.com/2019/09/15/best-use-of-train-val-test-splits-with-tips-for-medical-data/)\n",
    "\n",
    "# **What Have I learnt from this exercise?**\n",
    "My main Objective was to apply all the concepts learned in CSE5334 on the given problem and find which better suits the problem statement.I have also learnt drawbacks of certain models on the given data.\n",
    "Following are the concepts used in this exercise:\n",
    "\n",
    "\n",
    "*   Multinomial Naive Bayes (https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "*   Multinomial NB using tfidf\n",
    "*   Logistic Regression and hyper parameter tuning (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "*   Linear SVM (https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html)\n",
    "*   Hyper parameter tuning with Grid Search\n",
    "*   Stemming (https://www.guru99.com/stemming-lemmatization-python-nltk.html)\n",
    "*   Deep Learning using word2vec\n",
    "*   Voting ensemble classifier (https://scikit-learn.org/stable/modules/ensemble.html)\n",
    "\n",
    "Error and accuracy measurements used:\n",
    "*   Accuracy score of the model (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "*   Mean Square Error (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)\n",
    "*   Mean absolute Error (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)\n",
    "*   Frequency Tables / cross tables of features (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html)\n",
    "*   Confusion Matrix (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qVau6jec1D5b"
   },
   "source": [
    "**Pre-Req:**\n",
    "This entire code was developed on google colab and cvs file should be present in google drive. Name of the text file should be \"bgg-13m-reviews.csv\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "-imcQTZVA6so",
    "outputId": "3bffcb46-e977-4b83-9bf2-062f5d376bd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qYgOdO9jAfxo"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wW7B0BQJ34xW"
   },
   "source": [
    "# **Google drive authentication:**\n",
    "\n",
    "*   Save file in any folder of your Google Drive\n",
    "*   Get shareable link of your file and save it in a \"link\" variable\n",
    "*   Run the following code and copy authorization code and paste in the text box that appears\n",
    "*   Running the next code cell fetches the file from the link and loads into the dataframe\n",
    "\n",
    "Ref(https://www.marktechpost.com/2019/06/07/how-to-connect-google-colab-with-google-drive/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9Wcrnc6UIIt"
   },
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "j8MS5tPXUs2k",
    "outputId": "acee99f7-1e4c-4f07-a56b-6181d86a1810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13jK9-sEAkIoqg2_9odAukk9q_WXMoQDs\n"
     ]
    }
   ],
   "source": [
    "link = 'https://drive.google.com/open?id=13jK9-sEAkIoqg2_9odAukk9q_WXMoQDs'\n",
    "fluff, id = link.split('=')\n",
    "print (id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFX93ZgFVH8_"
   },
   "outputs": [],
   "source": [
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('bgg-13m-reviews.csv')  \n",
    "data = pd.read_csv('bgg-13m-reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfqvJG0Y6BhW"
   },
   "source": [
    "# **Data Columns**\n",
    "Given data contains the following coloums as displayed in the output\n",
    "*   User -- text\n",
    "*   Rating -- Float\n",
    "*   Comment -- text\n",
    "*   ID -- number\n",
    "*   Name -- text\n",
    "\n",
    "User, Name or ID cannot be selected as features for our model as they do not contribute to the rating for a game.\n",
    "Comment is user text given for a game. This is a main component for our model. \n",
    "Rating is numerical number given for the text review. We consider this as labels and train our model to predict correct labes for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "NAcqG_6dWBLE",
    "outputId": "214022f6-3598-4d59-c01e-4f3206922ae3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sidehacker</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Varthlokkur</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dougthonus</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Currently, this sits on my list as my favorite...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cypar7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I know it says how many plays, but many, many ...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ssmooth</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         user  ...  ID   name\n",
       "0           0   sidehacker  ...  13  Catan\n",
       "1           1  Varthlokkur  ...  13  Catan\n",
       "2           2   dougthonus  ...  13  Catan\n",
       "3           3       cypar7  ...  13  Catan\n",
       "4           4      ssmooth  ...  13  Catan\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nk3EF6py8xOF"
   },
   "source": [
    "# **Dropping NA rows**\n",
    "As seen in the above output, comment have NaN as its values. Comment is the most important feature in our model. The rows with NaN have no value in our process and should be removed. \n",
    "One positive side of this is that the data size is reduced and becomes a little more manageable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "yRIaCVwpWD1q",
    "outputId": "f0373a29-ea22-49fb-94d6-a4059dfc66f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with NA values 13170073\n",
      "Number of rows without NA values 2637756\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows with NA values',len(data['comment']))\n",
    "data = data.dropna(how='any',axis=0)\n",
    "print('Number of rows without NA values',len(data['comment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ufQKwOMP-B9j"
   },
   "source": [
    "# **Observing the Data**\n",
    "It is very important to understand how our data is to choose what models to use. As it is already clear that we are dealing with text data, it is important to see what is actually usefull  in it.\n",
    "\n",
    "Most of the text data by real time users contains information like punctuation and stop words that are not really useful in the process of our analysis.\n",
    "\n",
    "Below output shows the number of stopwords, numerics and uppercase letters we have have in each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "rB7Y8ytXhG6l",
    "outputId": "c48fe16a-439f-41f8-8ac5-b0a722e2b089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dougthonus</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Currently, this sits on my list as my favorite...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cypar7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I know it says how many plays, but many, many ...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>hreimer</td>\n",
       "      <td>10.0</td>\n",
       "      <td>i will never tire of this game.. Awesome</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>daredevil</td>\n",
       "      <td>10.0</td>\n",
       "      <td>This is probably the best game I ever played. ...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>hurkle</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Fantastic game. Got me hooked on games all ove...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0        user  rating  ... stopwords  numerics upper\n",
       "2            2  dougthonus    10.0  ...         5         0     0\n",
       "3            3      cypar7    10.0  ...         6         0     2\n",
       "7            7     hreimer    10.0  ...         4         0     0\n",
       "11          11   daredevil    10.0  ...         5         0     1\n",
       "16          16      hurkle    10.0  ...         4         0     0\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "data['stopwords'] = data['comment'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "data['numerics'] = data['comment'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "data['upper'] = data['comment'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jGWlu-34-xen"
   },
   "source": [
    "# **Cleaning the text**\n",
    "Text is just a sequence of words, or more precisely, a sequence of characters. But when we usually deal with language modelling, or natural language processing, we are more concerned about the words as a whole, instead of just worrying about character-level depth of our text data. One reason behind that is, that in the language models, individual characters don’t have a lot of “context”. Characters like ‘d’, ‘r’, ‘a’, ‘e’ don’t hold any context individually, but when rearranged in the form of a word, they might generate the word “read”, which might explain some activity you’re probably doing right now\n",
    "\n",
    "**Why cleaning/Pre-processing?**\n",
    "\n",
    "\n",
    "*   Text usually contains large number of words and keeping all of them increases the dimentionality of the problem. So to make model fitting easy, we need to remove words or sentances that is of no importance\n",
    "*   To reduce the noise in the text\n",
    "*   Help improve the performance of the classifier and speed up the classification process,\n",
    "\n",
    "Function description:\n",
    "\n",
    "**cleanText:**\n",
    "\n",
    "    Input: A single review text\n",
    "    output: Cleaned text\n",
    "    Process: Convert all the characters to lower case. Remove special characters and symbols. Remove stop words\n",
    "\n",
    "**convertRating:**\n",
    "\n",
    "    input: rating\n",
    "    output: rating as int\n",
    "**Why convert rating to int?**\n",
    "The rating column typically has continuous values having around 3000 unique values. To make it discrete and convert this problem into multi-class prediction problem, I have choosen to convert rating to int. After converting rating has 11 unique values (0 to 10). \n",
    "\n",
    "**printErrAcc**\n",
    "\n",
    "    input: test values and predicted values\n",
    "    output: prints the accuracy score, mean squared error and mean absolute error\n",
    "\n",
    "# **Error Measure Discription**\n",
    "**Accuracy Score**: The accuracy_score function computes the accuracy, either the fraction (default) or the count (normalize=False) of correct predictions.\n",
    "In multilabel classification, the function returns the subset accuracy. If the entire set of predicted labels for a sample strictly match with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0.\n",
    "\n",
    "**Mean Square error:** a risk metric corresponding to the expected value of the squared (quadratic) error or loss.\n",
    " MSE = 1/N(sum of (xi - yi)^2)\n",
    "\n",
    "**Mean Absolute error:**a risk metric corresponding to the expected value of the absolute error loss or -norm loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rxVJImyPW6eD"
   },
   "outputs": [],
   "source": [
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def cleanText(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[/(){}\\[\\]\\|@,;]', '', text)\n",
    "    text = re.sub('[^0-9a-z #+_]', '', text)\n",
    "    text = \" \" .join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return text\n",
    "\n",
    "def convertRating(num):\n",
    "    num = int(num)\n",
    "    return num\n",
    "\n",
    "def printErrAcc(test, pred):\n",
    "  print('accuracy %s' % accuracy_score(pred, test))\n",
    "  print('Mean Squared Error: ', mean_squared_error(test,pred))\n",
    "  print('Mean Absolute Error: ',mean_absolute_error(test, pred))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "7Yl8uu8_XOGM",
    "outputId": "d376a149-b5c7-4f25-f872-9c55155216ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dougthonus</td>\n",
       "      <td>10</td>\n",
       "      <td>currently sits list favorite game</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cypar7</td>\n",
       "      <td>10</td>\n",
       "      <td>know says many plays many many uncounted liked...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>hreimer</td>\n",
       "      <td>10</td>\n",
       "      <td>never tire game awesome</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>daredevil</td>\n",
       "      <td>10</td>\n",
       "      <td>probably best game ever played requires thinki...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>hurkle</td>\n",
       "      <td>10</td>\n",
       "      <td>fantastic game got hooked games</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0        user  rating  ... stopwords  numerics upper\n",
       "2            2  dougthonus      10  ...         5         0     0\n",
       "3            3      cypar7      10  ...         6         0     2\n",
       "7            7     hreimer      10  ...         4         0     0\n",
       "11          11   daredevil      10  ...         5         0     1\n",
       "16          16      hurkle      10  ...         4         0     0\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying cleaning function to comment and converting rating to int\n",
    "data['comment'] = data['comment'].apply(cleanText)\n",
    "data['rating'] = data['rating'].apply(convertRating)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GN9-S1_XHI_2"
   },
   "source": [
    "# **Looking for Simple Patterns**\n",
    "As this is a text classification, it is possible that identifying simple patterns may give us some insights. \n",
    "For example, it is possible that positive reviews may have more number of characters or words than negative reviews. If this pattern is consistant, we can get a very good accuracy with very simple model. (One debatable point here is, does the model under estimate? is it a good model for real world?)\n",
    "\n",
    "Below code computes the average word length and average number of words in all the rating labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0P6PGvKwYsWh"
   },
   "outputs": [],
   "source": [
    "data['length'] = data['comment'].astype(str).apply(len)\n",
    "data['num_of_words'] = data['comment'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "2293e6zbavJv",
    "outputId": "f38c7442-70df-4837-a305-02c2ab3849ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>length</th>\n",
       "      <th>num_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dougthonus</td>\n",
       "      <td>10</td>\n",
       "      <td>currently sits list favorite game</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cypar7</td>\n",
       "      <td>10</td>\n",
       "      <td>know says many plays many many uncounted liked...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>hreimer</td>\n",
       "      <td>10</td>\n",
       "      <td>never tire game awesome</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>daredevil</td>\n",
       "      <td>10</td>\n",
       "      <td>probably best game ever played requires thinki...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>hurkle</td>\n",
       "      <td>10</td>\n",
       "      <td>fantastic game got hooked games</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0        user  rating  ... upper  length num_of_words\n",
       "2            2  dougthonus      10  ...     0      33            5\n",
       "3            3      cypar7      10  ...     2      59           10\n",
       "7            7     hreimer      10  ...     0      23            4\n",
       "11          11   daredevil      10  ...     1      76           10\n",
       "16          16      hurkle      10  ...     0      31            5\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "colab_type": "code",
    "id": "_cA5rYgRa3I9",
    "outputId": "c7cf0756-5f23-472a-c5f3-6f4d4d4f6003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating and length of the review\n",
      "rating\n",
      "0     170.636364\n",
      "1     134.817028\n",
      "2     145.546466\n",
      "3     147.791271\n",
      "4     142.781897\n",
      "5     134.971907\n",
      "6     134.938101\n",
      "7     133.438831\n",
      "8     140.949610\n",
      "9     152.652159\n",
      "10    155.112531\n",
      "Name: length, dtype: float64\n",
      "Rating and number of words in the review\n",
      "rating\n",
      "0     26.909091\n",
      "1     20.326415\n",
      "2     21.916677\n",
      "3     22.276462\n",
      "4     21.554762\n",
      "5     20.441929\n",
      "6     20.463327\n",
      "7     20.174021\n",
      "8     21.189036\n",
      "9     22.836146\n",
      "10    23.200778\n",
      "Name: num_of_words, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "print('Rating and length of the review')\n",
    "print(data.groupby('rating')['length'].mean())\n",
    "\n",
    "print('Rating and number of words in the review')\n",
    "print(data.groupby('rating')['num_of_words'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aO5YHHGzLQRK"
   },
   "source": [
    "Number of words or number of characters does not really provide us with any insights. \n",
    "Next we will try to see how are reviews distributed among rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "OPudBw8QXq89",
    "outputId": "95ea7448-a8cf-4b5a-8010-93d572cc558d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "plt.figure(figsize=(10,4))\n",
    "data.rating.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1jt3C04LoJy"
   },
   "source": [
    "It is very unfortunate that the reviews are not equally distrubuted among all the rating labels. \n",
    "As it can be seen, rating of type 7 have more number of data than any other type. \n",
    "\n",
    "# **What happens when the data is unevenly distrubuted?**\n",
    "\n",
    "\n",
    "*   The classification accuracy drops rapidly because of uneven distribution of features\n",
    "*   Classifier will prefer the class with more values\n",
    "\n",
    "This is how real world data is. Among all thiese conditions, we will fit different type of models and check wich performs better\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "colab_type": "code",
    "id": "RdM9zrxFc36L",
    "outputId": "397fab1d-6e06-4576-dd16-75d72cd6f31b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yellowbrick\n",
    "from yellowbrick.text import FreqDistVisualizer\n",
    "vectorizer = CountVectorizer()\n",
    "docs = vectorizer.fit_transform(data['comment'])\n",
    "features = vectorizer.get_feature_names()\n",
    "visualizer = FreqDistVisualizer(features=features)\n",
    "visualizer.fit(docs)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNH_6rJtXoLG"
   },
   "outputs": [],
   "source": [
    "#splitting train and test data\n",
    "x = data.comment\n",
    "y = data.rating\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=40, \n",
    "                                                  test_size=0.3, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sy2___4TNUSE"
   },
   "source": [
    "# **Multinomial Naive Bayes**\n",
    "MultinomialNB implements the naive Bayes algorithm for multinomially distributed data, and is one of the two classic naive Bayes variants used in text classification where the data are typically represented as word vector counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "colab_type": "code",
    "id": "KxcJjCVZYHM5",
    "outputId": "4e07c89c-bc04-4405-df3b-3f8c41fcb99b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.3151074081890293\n",
      "Mean Squared Error:  2.455591683336977\n",
      "Mean Absolute Error:  1.113061983225645\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>54</td>\n",
       "      <td>181</td>\n",
       "      <td>405</td>\n",
       "      <td>920</td>\n",
       "      <td>2411</td>\n",
       "      <td>1680</td>\n",
       "      <td>422</td>\n",
       "      <td>93</td>\n",
       "      <td>77</td>\n",
       "      <td>6360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>128</td>\n",
       "      <td>218</td>\n",
       "      <td>586</td>\n",
       "      <td>1872</td>\n",
       "      <td>5726</td>\n",
       "      <td>2803</td>\n",
       "      <td>552</td>\n",
       "      <td>112</td>\n",
       "      <td>39</td>\n",
       "      <td>12051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "      <td>225</td>\n",
       "      <td>600</td>\n",
       "      <td>3015</td>\n",
       "      <td>11604</td>\n",
       "      <td>6004</td>\n",
       "      <td>1166</td>\n",
       "      <td>165</td>\n",
       "      <td>54</td>\n",
       "      <td>22881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>49</td>\n",
       "      <td>108</td>\n",
       "      <td>586</td>\n",
       "      <td>3988</td>\n",
       "      <td>20549</td>\n",
       "      <td>12102</td>\n",
       "      <td>2172</td>\n",
       "      <td>271</td>\n",
       "      <td>76</td>\n",
       "      <td>39925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>82</td>\n",
       "      <td>419</td>\n",
       "      <td>4851</td>\n",
       "      <td>35558</td>\n",
       "      <td>28736</td>\n",
       "      <td>4903</td>\n",
       "      <td>580</td>\n",
       "      <td>189</td>\n",
       "      <td>75381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>69</td>\n",
       "      <td>77</td>\n",
       "      <td>301</td>\n",
       "      <td>3412</td>\n",
       "      <td>55544</td>\n",
       "      <td>77922</td>\n",
       "      <td>14769</td>\n",
       "      <td>1375</td>\n",
       "      <td>441</td>\n",
       "      <td>153982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>68</td>\n",
       "      <td>77</td>\n",
       "      <td>213</td>\n",
       "      <td>1568</td>\n",
       "      <td>38173</td>\n",
       "      <td>127424</td>\n",
       "      <td>36968</td>\n",
       "      <td>3177</td>\n",
       "      <td>952</td>\n",
       "      <td>208734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>96</td>\n",
       "      <td>621</td>\n",
       "      <td>15157</td>\n",
       "      <td>84433</td>\n",
       "      <td>50955</td>\n",
       "      <td>5605</td>\n",
       "      <td>1337</td>\n",
       "      <td>158400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>242</td>\n",
       "      <td>4778</td>\n",
       "      <td>29233</td>\n",
       "      <td>32724</td>\n",
       "      <td>6751</td>\n",
       "      <td>1546</td>\n",
       "      <td>75413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>130</td>\n",
       "      <td>1915</td>\n",
       "      <td>10823</td>\n",
       "      <td>16973</td>\n",
       "      <td>5517</td>\n",
       "      <td>2772</td>\n",
       "      <td>38197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>9</td>\n",
       "      <td>552</td>\n",
       "      <td>516</td>\n",
       "      <td>1050</td>\n",
       "      <td>3270</td>\n",
       "      <td>20620</td>\n",
       "      <td>191416</td>\n",
       "      <td>381161</td>\n",
       "      <td>161604</td>\n",
       "      <td>23646</td>\n",
       "      <td>7483</td>\n",
       "      <td>791327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0    1    2     3     4  ...       7       8      9    10     All\n",
       "True                                ...                                     \n",
       "0          0    0    0     0     0  ...       1       0      0     0       3\n",
       "1          0  117   54   181   405  ...    1680     422     93    77    6360\n",
       "2          1   14  128   218   586  ...    2803     552    112    39   12051\n",
       "3          0   13   35   225   600  ...    6004    1166    165    54   22881\n",
       "4          1   23   49   108   586  ...   12102    2172    271    76   39925\n",
       "5          0   26   37    82   419  ...   28736    4903    580   189   75381\n",
       "6          1   71   69    77   301  ...   77922   14769   1375   441  153982\n",
       "7          4  110   68    77   213  ...  127424   36968   3177   952  208734\n",
       "8          1  104   47    44    96  ...   84433   50955   5605  1337  158400\n",
       "9          1   59   18    26    35  ...   29233   32724   6751  1546   75413\n",
       "10         0   15   11    12    29  ...   10823   16973   5517  2772   38197\n",
       "All        9  552  516  1050  3270  ...  381161  161604  23646  7483  791327\n",
       "\n",
       "[12 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(x_test)\n",
    "\n",
    "printErrAcc(y_test, y_pred)\n",
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u_0QvsIjN8Pq"
   },
   "source": [
    "Naive Bayes gives us an accuracy of 31.5%. \n",
    "It is not a great number but considering our real world problems, this is not bad.\n",
    "\n",
    "Our cross table gives more information on how the classifier worked.\n",
    "As we can see, of total 208734 values in rating-7, correctly classified rows are 127424\n",
    "for rating having fewer data, the numbers are also very low. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UcZnX77eNi7U"
   },
   "source": [
    "# **Multinomial NB with TFIDF**\n",
    "**TFIDF**:\n",
    "\n",
    "Tf-idf stands for term frequency-inverse document frequency, and the tf-idf weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus. Variations of the tf-idf weighting scheme are often used by search engines as a central tool in scoring and ranking a document's relevance given a user query.\n",
    "\n",
    "One of the simplest ranking functions is computed by summing the tf-idf for each query term; many more sophisticated ranking functions are variants of this simple model.\n",
    "\n",
    "Tf-idf can be successfully used for stop-words filtering in various subject fields including text summarization and classification.\n",
    "\n",
    "**How is TFIDF computed?**\n",
    "\n",
    "*  TF: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization:\n",
    "\n",
    "  TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "\n",
    "*  IDF: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following:\n",
    "\n",
    "  IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
    "\n",
    "Ref(https://en.wikipedia.org/wiki/Tf%E2%80%93idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "colab_type": "code",
    "id": "Srg7FfApSB1k",
    "outputId": "c61cf1e0-3bb1-4c41-8765-4b339395e121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.2849517329751165\n",
      "Mean Squared Error:  2.8622427896432194\n",
      "Mean Absolute Error:  1.2280359446853197\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>61</td>\n",
       "      <td>1441</td>\n",
       "      <td>4661</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>108</td>\n",
       "      <td>3242</td>\n",
       "      <td>8421</td>\n",
       "      <td>175</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>203</td>\n",
       "      <td>5714</td>\n",
       "      <td>16568</td>\n",
       "      <td>333</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>22881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>291</td>\n",
       "      <td>9043</td>\n",
       "      <td>29947</td>\n",
       "      <td>557</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>39925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>456</td>\n",
       "      <td>13976</td>\n",
       "      <td>59568</td>\n",
       "      <td>1319</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>75381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>253</td>\n",
       "      <td>16965</td>\n",
       "      <td>132749</td>\n",
       "      <td>3910</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>153982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>117</td>\n",
       "      <td>7994</td>\n",
       "      <td>190248</td>\n",
       "      <td>10196</td>\n",
       "      <td>151</td>\n",
       "      <td>12</td>\n",
       "      <td>208734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>2939</td>\n",
       "      <td>137853</td>\n",
       "      <td>17274</td>\n",
       "      <td>272</td>\n",
       "      <td>15</td>\n",
       "      <td>158400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>962</td>\n",
       "      <td>59874</td>\n",
       "      <td>14220</td>\n",
       "      <td>309</td>\n",
       "      <td>24</td>\n",
       "      <td>75413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>481</td>\n",
       "      <td>27079</td>\n",
       "      <td>10330</td>\n",
       "      <td>195</td>\n",
       "      <td>105</td>\n",
       "      <td>38197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>36</td>\n",
       "      <td>206</td>\n",
       "      <td>1564</td>\n",
       "      <td>62757</td>\n",
       "      <td>666971</td>\n",
       "      <td>58471</td>\n",
       "      <td>1093</td>\n",
       "      <td>166</td>\n",
       "      <td>791327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  1   2   3    4     5      6       7      8     9   10     All\n",
       "True                                                                    \n",
       "0          0   0   0    0     0      0       3      0     0    0       3\n",
       "1          7   0   8   21    61   1441    4661    157     3    1    6360\n",
       "2          0  54   3   42   108   3242    8421    175     6    0   12051\n",
       "3          0   0  14   39   203   5714   16568    333    10    0   22881\n",
       "4          0   2   5   58   291   9043   29947    557    22    0   39925\n",
       "5          0   0   6   15   456  13976   59568   1319    36    5   75381\n",
       "6          0   0   0   12   253  16965  132749   3910    89    4  153982\n",
       "7          0   0   0   16   117   7994  190248  10196   151   12  208734\n",
       "8          0   0   0    2    45   2939  137853  17274   272   15  158400\n",
       "9          0   0   0    1    23    962   59874  14220   309   24   75413\n",
       "10         0   0   0    0     7    481   27079  10330   195  105   38197\n",
       "All        7  56  36  206  1564  62757  666971  58471  1093  166  791327"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_with_tf = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb_with_tf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = nb_with_tf.predict(x_test)\n",
    "\n",
    "\n",
    "printErrAcc(y_test, y_pred)\n",
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8BLgA9UP-OW"
   },
   "source": [
    "Unfortunately, TFIDF did not work in out case. The accuracy for the above model is bad tha the previous NB model.\n",
    "\n",
    "But, TFIDF on its own is a very promising concept. So i will continue to use TFIDF in the next classifiers I use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rbtZ6gYQQSXC"
   },
   "source": [
    "# **Logistic Regression**\n",
    "\n",
    "Logistic regression, despite its name, is a linear model for classification rather than regression. Logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a logistic function.\n",
    "\n",
    "Unfortunately due to RAM limits, I was unable to use bi-grams and tri-grams for constructing the model. Colab keeps crashing if i just use bi-grams. \n",
    "If there is a good RAM, I believe n-grams will give a very good accuracy boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8V94Wb3W6Nr"
   },
   "outputs": [],
   "source": [
    "x, x_val, y, y_val = train_test_split(x_train, y_train, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 849
    },
    "colab_type": "code",
    "id": "3ELBMHoGtK8x",
    "outputId": "ff38aaa6-366c-471c-c871-bc17c8cb186e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.01\n",
      "accuracy 0.31183960399256944\n",
      "Mean Squared Error:  2.5873171471434064\n",
      "Mean Absolute Error:  1.1402327735142952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1\n",
      "accuracy 0.32535036078631013\n",
      "Mean Squared Error:  2.365230923096642\n",
      "Mean Absolute Error:  1.0814237925799155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.5\n",
      "accuracy 0.32648227480417163\n",
      "Mean Squared Error:  2.3459161733724\n",
      "Mean Absolute Error:  1.0774214745933144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.1\n",
      "accuracy 0.3251878850899664\n",
      "Mean Squared Error:  2.388649086796322\n",
      "Mean Absolute Error:  1.0866771734283636\n"
     ]
    }
   ],
   "source": [
    "hyperParam = [0.01,1,0.5,0.1]\n",
    "sqArr = list()\n",
    "absArr = list()\n",
    "accur = list()\n",
    "for i in hyperParam:\n",
    "  logistic = Pipeline([('vect', CountVectorizer()), \n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(C=i)),\n",
    "                ])\n",
    "\n",
    "  logistic.fit(x, y)\n",
    "\n",
    "  y_pred = logistic.predict(x_val)\n",
    "  print(\"alpha: \",i)\n",
    "  printErrAcc(y_val, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "colab_type": "code",
    "id": "3gOk4XnKfvmH",
    "outputId": "7a209e86-5e4d-40b1-9cea-fe7994f52e0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.5\n",
      "accuracy 0.32588550624457396\n",
      "Mean Squared Error:  2.3594127332948327\n",
      "Mean Absolute Error:  1.0792163037530629\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>193</td>\n",
       "      <td>652</td>\n",
       "      <td>566</td>\n",
       "      <td>571</td>\n",
       "      <td>539</td>\n",
       "      <td>1466</td>\n",
       "      <td>1839</td>\n",
       "      <td>397</td>\n",
       "      <td>36</td>\n",
       "      <td>101</td>\n",
       "      <td>6360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>797</td>\n",
       "      <td>995</td>\n",
       "      <td>1341</td>\n",
       "      <td>1505</td>\n",
       "      <td>3616</td>\n",
       "      <td>2930</td>\n",
       "      <td>603</td>\n",
       "      <td>90</td>\n",
       "      <td>96</td>\n",
       "      <td>12051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>623</td>\n",
       "      <td>1091</td>\n",
       "      <td>2214</td>\n",
       "      <td>3197</td>\n",
       "      <td>8221</td>\n",
       "      <td>6058</td>\n",
       "      <td>1159</td>\n",
       "      <td>133</td>\n",
       "      <td>141</td>\n",
       "      <td>22881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>465</td>\n",
       "      <td>859</td>\n",
       "      <td>2605</td>\n",
       "      <td>5450</td>\n",
       "      <td>15917</td>\n",
       "      <td>12032</td>\n",
       "      <td>2153</td>\n",
       "      <td>193</td>\n",
       "      <td>208</td>\n",
       "      <td>39925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>364</td>\n",
       "      <td>664</td>\n",
       "      <td>2384</td>\n",
       "      <td>7574</td>\n",
       "      <td>30272</td>\n",
       "      <td>28613</td>\n",
       "      <td>4711</td>\n",
       "      <td>376</td>\n",
       "      <td>378</td>\n",
       "      <td>75381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48</td>\n",
       "      <td>230</td>\n",
       "      <td>421</td>\n",
       "      <td>1538</td>\n",
       "      <td>6033</td>\n",
       "      <td>49232</td>\n",
       "      <td>80315</td>\n",
       "      <td>14363</td>\n",
       "      <td>1010</td>\n",
       "      <td>792</td>\n",
       "      <td>153982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45</td>\n",
       "      <td>171</td>\n",
       "      <td>200</td>\n",
       "      <td>699</td>\n",
       "      <td>2555</td>\n",
       "      <td>32736</td>\n",
       "      <td>129652</td>\n",
       "      <td>38101</td>\n",
       "      <td>2949</td>\n",
       "      <td>1626</td>\n",
       "      <td>208734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37</td>\n",
       "      <td>99</td>\n",
       "      <td>105</td>\n",
       "      <td>299</td>\n",
       "      <td>1042</td>\n",
       "      <td>12300</td>\n",
       "      <td>82323</td>\n",
       "      <td>52811</td>\n",
       "      <td>6358</td>\n",
       "      <td>3026</td>\n",
       "      <td>158400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28</td>\n",
       "      <td>56</td>\n",
       "      <td>45</td>\n",
       "      <td>115</td>\n",
       "      <td>326</td>\n",
       "      <td>3932</td>\n",
       "      <td>27753</td>\n",
       "      <td>31203</td>\n",
       "      <td>7716</td>\n",
       "      <td>4239</td>\n",
       "      <td>75413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "      <td>71</td>\n",
       "      <td>187</td>\n",
       "      <td>1684</td>\n",
       "      <td>10327</td>\n",
       "      <td>13985</td>\n",
       "      <td>5611</td>\n",
       "      <td>6211</td>\n",
       "      <td>38197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>591</td>\n",
       "      <td>3512</td>\n",
       "      <td>4982</td>\n",
       "      <td>11839</td>\n",
       "      <td>28408</td>\n",
       "      <td>159376</td>\n",
       "      <td>381843</td>\n",
       "      <td>159486</td>\n",
       "      <td>24472</td>\n",
       "      <td>16818</td>\n",
       "      <td>791327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    1     2     3      4      5  ...       7       8      9     10     All\n",
       "True                                      ...                                      \n",
       "0            0     0     0      2      0  ...       1       0      0      0       3\n",
       "1          193   652   566    571    539  ...    1839     397     36    101    6360\n",
       "2           78   797   995   1341   1505  ...    2930     603     90     96   12051\n",
       "3           44   623  1091   2214   3197  ...    6058    1159    133    141   22881\n",
       "4           43   465   859   2605   5450  ...   12032    2153    193    208   39925\n",
       "5           45   364   664   2384   7574  ...   28613    4711    376    378   75381\n",
       "6           48   230   421   1538   6033  ...   80315   14363   1010    792  153982\n",
       "7           45   171   200    699   2555  ...  129652   38101   2949   1626  208734\n",
       "8           37    99   105    299   1042  ...   82323   52811   6358   3026  158400\n",
       "9           28    56    45    115    326  ...   27753   31203   7716   4239   75413\n",
       "10          30    55    36     71    187  ...   10327   13985   5611   6211   38197\n",
       "All        591  3512  4982  11839  28408  ...  381843  159486  24472  16818  791327\n",
       "\n",
       "[12 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg = Pipeline([('vect', CountVectorizer()), \n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(C=0.5)),\n",
    "                ])\n",
    "logReg.fit(x_train, y_train)\n",
    "\n",
    "y_pred = logReg.predict(x_test)\n",
    "print(\"alpha: \",0.5)\n",
    "printErrAcc(y_test, y_pred)\n",
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hrnFyKFzRHqP"
   },
   "source": [
    "**Is our data suitable for Logistic Regression?**\n",
    "\n",
    "Logistic regression is more suitable for Binary classification problems like cancer detection. We have multiple target values and that is one of the issue for logistic regression.\n",
    "One of the assumptions of logistic regression is \"The independent variables should be independent of each other. That is, the model should have little or no multicollinearity\". This difficult to hold completley in real world data.\n",
    "\n",
    "so, our data is partially suitable for logistic regression and our model gives good accuracy considering above points\n",
    "\n",
    "# **Linear SVM**\n",
    "Support vector machines (SVMs) are a set of supervised learning methods\n",
    "advantages:\n",
    "*   Effective in high dimensional spaces.\n",
    "*   Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "*   Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "QULvjSU_ZQuh",
    "outputId": "1aec91e2-2c9e-45e2-a124-b1a108d34d0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.2636988248852876\n",
      "Mean Squared Error:  3.625226992128412\n",
      "Mean Absolute Error:  1.3747818537722079\n"
     ]
    }
   ],
   "source": [
    "linearSVM = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "linearSVM.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = linearSVM.predict(x_test)\n",
    "printErrAcc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "hEtnoS8nwvqG",
    "outputId": "f7ff80ee-4f52-41bf-c466-c9417cc5b915"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.17      0.21      0.19      6360\n",
      "           2       0.11      0.10      0.11     12051\n",
      "           3       0.11      0.08      0.09     22881\n",
      "           4       0.13      0.10      0.11     39925\n",
      "           5       0.18      0.18      0.18     75381\n",
      "           6       0.28      0.26      0.27    153982\n",
      "           7       0.33      0.40      0.36    208734\n",
      "           8       0.29      0.26      0.28    158400\n",
      "           9       0.19      0.17      0.18     75413\n",
      "          10       0.21      0.23      0.22     38197\n",
      "\n",
      "    accuracy                           0.26    791327\n",
      "   macro avg       0.18      0.18      0.18    791327\n",
      "weighted avg       0.26      0.26      0.26    791327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfG4VdMbUjke"
   },
   "source": [
    "It is very shocking that a very good model like SVM have given low accuracy and large error. Looking for what might be the problem, I have found bellow points:\n",
    "*  SVM does not perform very well, when the data set has more noise i.e. target classes are overlapping. We have converted the rating into discrete values. otherwise they are continuous and overlapping.\n",
    "*   As the support vector classifier works by putting data points, above and below the classifying hyper plane there is no probabilistic explanation for the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "colab_type": "code",
    "id": "T3d19BbMyAb7",
    "outputId": "5aba1705-1b66-46c9-ac2f-02624be37db7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1348</td>\n",
       "      <td>728</td>\n",
       "      <td>456</td>\n",
       "      <td>549</td>\n",
       "      <td>870</td>\n",
       "      <td>699</td>\n",
       "      <td>892</td>\n",
       "      <td>383</td>\n",
       "      <td>213</td>\n",
       "      <td>222</td>\n",
       "      <td>6360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>925</td>\n",
       "      <td>1260</td>\n",
       "      <td>1101</td>\n",
       "      <td>1428</td>\n",
       "      <td>2191</td>\n",
       "      <td>1937</td>\n",
       "      <td>1803</td>\n",
       "      <td>745</td>\n",
       "      <td>398</td>\n",
       "      <td>263</td>\n",
       "      <td>12051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>914</td>\n",
       "      <td>1403</td>\n",
       "      <td>1803</td>\n",
       "      <td>2570</td>\n",
       "      <td>4570</td>\n",
       "      <td>4599</td>\n",
       "      <td>4120</td>\n",
       "      <td>1550</td>\n",
       "      <td>843</td>\n",
       "      <td>509</td>\n",
       "      <td>22881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>840</td>\n",
       "      <td>1410</td>\n",
       "      <td>2181</td>\n",
       "      <td>3865</td>\n",
       "      <td>8038</td>\n",
       "      <td>9799</td>\n",
       "      <td>8324</td>\n",
       "      <td>3107</td>\n",
       "      <td>1564</td>\n",
       "      <td>797</td>\n",
       "      <td>39925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>791</td>\n",
       "      <td>1582</td>\n",
       "      <td>2627</td>\n",
       "      <td>5166</td>\n",
       "      <td>13829</td>\n",
       "      <td>20573</td>\n",
       "      <td>19380</td>\n",
       "      <td>6794</td>\n",
       "      <td>3085</td>\n",
       "      <td>1554</td>\n",
       "      <td>75381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>943</td>\n",
       "      <td>1861</td>\n",
       "      <td>3099</td>\n",
       "      <td>6518</td>\n",
       "      <td>18531</td>\n",
       "      <td>39795</td>\n",
       "      <td>52204</td>\n",
       "      <td>19416</td>\n",
       "      <td>7881</td>\n",
       "      <td>3734</td>\n",
       "      <td>153982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>984</td>\n",
       "      <td>1673</td>\n",
       "      <td>2543</td>\n",
       "      <td>5665</td>\n",
       "      <td>15098</td>\n",
       "      <td>37387</td>\n",
       "      <td>83716</td>\n",
       "      <td>39391</td>\n",
       "      <td>15090</td>\n",
       "      <td>7187</td>\n",
       "      <td>208734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>643</td>\n",
       "      <td>1042</td>\n",
       "      <td>1377</td>\n",
       "      <td>3195</td>\n",
       "      <td>8148</td>\n",
       "      <td>19746</td>\n",
       "      <td>55217</td>\n",
       "      <td>41803</td>\n",
       "      <td>17612</td>\n",
       "      <td>9617</td>\n",
       "      <td>158400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>348</td>\n",
       "      <td>417</td>\n",
       "      <td>554</td>\n",
       "      <td>1313</td>\n",
       "      <td>3141</td>\n",
       "      <td>6838</td>\n",
       "      <td>19941</td>\n",
       "      <td>21648</td>\n",
       "      <td>12534</td>\n",
       "      <td>8679</td>\n",
       "      <td>75413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>217</td>\n",
       "      <td>235</td>\n",
       "      <td>233</td>\n",
       "      <td>571</td>\n",
       "      <td>1406</td>\n",
       "      <td>2630</td>\n",
       "      <td>7531</td>\n",
       "      <td>9630</td>\n",
       "      <td>7025</td>\n",
       "      <td>8719</td>\n",
       "      <td>38197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>7953</td>\n",
       "      <td>11611</td>\n",
       "      <td>15974</td>\n",
       "      <td>30841</td>\n",
       "      <td>75822</td>\n",
       "      <td>144003</td>\n",
       "      <td>253129</td>\n",
       "      <td>144467</td>\n",
       "      <td>66245</td>\n",
       "      <td>41282</td>\n",
       "      <td>791327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     1      2      3      4  ...       8      9     10     All\n",
       "True                                  ...                              \n",
       "0             0      0      0      1  ...       0      0      1       3\n",
       "1          1348    728    456    549  ...     383    213    222    6360\n",
       "2           925   1260   1101   1428  ...     745    398    263   12051\n",
       "3           914   1403   1803   2570  ...    1550    843    509   22881\n",
       "4           840   1410   2181   3865  ...    3107   1564    797   39925\n",
       "5           791   1582   2627   5166  ...    6794   3085   1554   75381\n",
       "6           943   1861   3099   6518  ...   19416   7881   3734  153982\n",
       "7           984   1673   2543   5665  ...   39391  15090   7187  208734\n",
       "8           643   1042   1377   3195  ...   41803  17612   9617  158400\n",
       "9           348    417    554   1313  ...   21648  12534   8679   75413\n",
       "10          217    235    233    571  ...    9630   7025   8719   38197\n",
       "All        7953  11611  15974  30841  ...  144467  66245  41282  791327\n",
       "\n",
       "[12 rows x 11 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "UqK4zb7kzXkR",
    "outputId": "00dc4932-eabb-4d24-c5a1-961f1b8d9d34"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "plt.imshow(conf, cmap='binary', interpolation='None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bn0_VhjLVir-"
   },
   "source": [
    "# **Hyperparameter tuning with Grid Search**\n",
    "Grid-search is used to find the optimal hyperparameters of a model which results in the most ‘accurate’ predictions\n",
    "\n",
    "I have done grid search on Naive bayes and linear SVM. \n",
    "The accuracy has improved...!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOqgDqaPeuN5"
   },
   "outputs": [],
   "source": [
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
    "\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],'tfidf__use_idf': (True, False),'clf__alpha': (1e-2, 1e-3),}\n",
    "\n",
    "gs_nb = GridSearchCV(text_clf, parameters, cv=5)\n",
    "gs_nb = gs_nb.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "eiFbwJ1E8mQ-",
    "outputId": "42ca8fe2-8968-4908-c24e-f3c28ce663ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.31781046267851343\n",
      "Mean Squared Error:  2.378909098261528\n",
      "Mean Absolute Error:  1.097527318036665\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs_nb.predict(x_test)\n",
    "printErrAcc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QxjPvsP9FBS"
   },
   "outputs": [],
   "source": [
    "svm = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', SGDClassifier()),])\n",
    "\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],'tfidf__use_idf': (True, False),'clf__alpha': (1e-2, 1e-3),}\n",
    "\n",
    "gs_svm = GridSearchCV(svm, parameters, cv=5)\n",
    "gs_svm = gs_svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "RtIr2kPZeILW",
    "outputId": "1f9b6dc2-e04f-4554-8db6-c29019b0b3e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.30834408531492036\n",
      "Mean Squared Error:  2.738767917687631\n",
      "Mean Absolute Error:  1.168721653627388\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs_svm.predict(x_test)\n",
    "printErrAcc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_dLvvyBNYENL"
   },
   "source": [
    "# **Stemming**\n",
    "\n",
    "Stemming is the process of producing morphological variants of a root/base word. Stemming programs are commonly referred to as stemming algorithms or stemmers. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”.\n",
    "\n",
    "This is taking text cleaning a step ahead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FthkArve_BYV"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PWUmAYLI_Deb"
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "lxYDSq65_Mqy",
    "outputId": "f0614200-a1e1-46c9-f90d-1a98a24d73aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.2973280359092563\n",
      "Mean Squared Error:  3.5736496117918235\n",
      "Mean Absolute Error:  1.2743653706174936\n"
     ]
    }
   ],
   "source": [
    "stemmed = Pipeline([('vect', stemmed_count_vect),('tfidf', TfidfTransformer()),\n",
    "('mnb', MultinomialNB(fit_prior=False)),])\n",
    "\n",
    "stemmed = stemmed.fit(x_train, y_train)\n",
    "y_pred = stemmed.predict(x_test)\n",
    "\n",
    "printErrAcc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "HL8MLEbYCbOL",
    "outputId": "db14de05-d5b5-4f91-a6cf-1d5a42a49a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.2643606696591047\n",
      "Mean Squared Error:  3.640573820211088\n",
      "Mean Absolute Error:  1.3775551983501153\n"
     ]
    }
   ],
   "source": [
    "stemmed = Pipeline([('vect', stemmed_count_vect),('tfidf', TfidfTransformer()),\n",
    "('mnb', SGDClassifier()),])\n",
    "\n",
    "stemmed = stemmed.fit(x_train, y_train)\n",
    "y_pred = stemmed.predict(x_test)\n",
    "\n",
    "printErrAcc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f0w1tuVmYlbh"
   },
   "source": [
    "In our case, stemming is not showing any good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "sLGB8TkMFSNf",
    "outputId": "7656224c-4a0a-4306-961f-c3b39ebc6420"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = confusion_matrix(y_test, y_pred)\n",
    "plt.imshow(conf, cmap='binary', interpolation='None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g_xH42-jY5jg"
   },
   "source": [
    "# **Word2Vec using gensim**\n",
    "\n",
    "The idea behind Word2vec is rather simple: we want to use the surrounding words to represent the target words with a Neural Network whose hidden layer encodes the word representation.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "I haven't used entire data in this method because of RAM restrictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "twhwC42wGn5-",
    "outputId": "817772d5-a902-4aeb-d07e-9ad7da0d06b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.4)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.0.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.13.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
      "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.5)\n",
      "Requirement already satisfied: botocore<1.17.0,>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.16.3)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.9)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "Uf703YgPg0ml",
    "outputId": "75de4190-2e8f-475f-8dad-855e6f51414a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "wv = KeyedVectors.load_word2vec_format(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tgg_2ujBZKYG"
   },
   "source": [
    "I have tried writing the below function based on BOW concept.\n",
    "Re-Training the model.BOW based approaches that includes averaging, summation, weighted addition. The common way is to average the two word vectors. Therefore, we will follow the most common way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2qZIU00svI9"
   },
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-632ak26tTiW"
   },
   "outputs": [],
   "source": [
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "    \n",
    "train, test = train_test_split(data, test_size=0.3, random_state = 42)\n",
    "train_data = train[:25000]\n",
    "test_data = test[:7500]\n",
    "\n",
    "test_tokenized = test_data.apply(lambda r: w2v_tokenize_text(r['comment']), axis=1).values\n",
    "train_tokenized = train_data.apply(lambda r: w2v_tokenize_text(r['comment']), axis=1).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "sRG1kMPDKqap",
    "outputId": "df167719-d955-465c-b2b8-b4e65544e0f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(test_tokenized))\n",
    "print(len(train_tokenized))\n",
    "yTrain_data = train_data['rating']\n",
    "yTest_data = test_data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14yDCEkgKvUg"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XrUp9EtALNJG",
    "outputId": "05e2598d-761b-4209-f8a0-99c1118a7db4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.2776\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(X_train_word_average, yTrain_data)\n",
    "y_pred = logreg.predict(X_test_word_average)\n",
    "print('accuracy %s' % accuracy_score(y_pred, yTest_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kyEsxF-ZXNA"
   },
   "source": [
    "# **Voting Ensemble**\n",
    "\n",
    "The idea behind the VotingClassifier is to combine conceptually different machine learning classifiers and use a majority vote or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing model in order to balance out their individual weaknesses\n",
    "\n",
    "In our case, voting ensemble have given us a good accuracy when compared to linear SVM and nb with tifidf individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "z1SejJnIOcNg",
    "outputId": "a1f0a7c8-0b6e-4b79-ab5b-9d153319085c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3154694819703437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "estimators = []\n",
    "estimators.append(('logistic', logReg))\n",
    "estimators.append(('naivebayes', nb))\n",
    "estimators.append(('svm', linearSVM))\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = model_selection.cross_val_score(ensemble, x_train, y_train, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2UojOAxH6FxR"
   },
   "source": [
    "# **Web Server and deployment of the model**\n",
    "\n",
    "Step1: Choosing the right model. I have choosen to do ensembling the best 3 models with highest accuracy. \n",
    "\n",
    "Step2 : Deployment. Having selected the right model, I have converted my phython/jupyter notebook to JOBLIL format for deployment of AWS.\n",
    "\n",
    "Step3: Train the model with all the data available.\n",
    "\n",
    "Step4: Set up Front end. My front end is written in jQuery and AJAX that calls the model.\n",
    "\n",
    "Step5: Sending the input to trained model. \n",
    "\n",
    "Step6: Displaying output. \n",
    "\n",
    "Link to page: \"http://ldeepika.uta.cloud/MyPortfolio/predict.html\"\n",
    "\n",
    "![Example-bad review](https://drive.google.com/open?id=1uvvZG7nPPnYOAiR3dLJRVS9X85Qf3bf7)\n",
    "\n",
    "![Example-good review](https://drive.google.com/open?id=1Tyt68sM0tPi9W9Lapjf39-SSKzh4cILq)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
